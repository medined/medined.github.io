---
layout: post
title: Entity Extraction Links (also Named entity recognition)
date: '2009-10-12T22:21:00.004-04:00'
author: David Medinets
modified_time: '2013-09-19T19:34:01.331-04:00'
blogger_id: tag:blogger.com,1999:blog-3207985.post-5910480115930456203
blogger_orig_url: http://affy.blogspot.com/2009/10/entity-extraction-links.html
year: 2009
---

Entity Extraction Links (also Named entity recognition)


<ul>
<li>Websites</li>
<ul>
<li><a href="http://semanticproxy.com/index.html">Semantic Proxy</a></li>
</ul>
<li>Software</li>
<ul>
<li>Ruby</li>
<li><code><a href="http://github.com/hypomodern/flex-attributes/">http://github.com/hypomodern/flex-attributes/</a></code> - Originally by Eric Anderson, some of that code still remains. If you’re not into this version, check his out at rubyforge.org/projects/flex-attributes/ See Hypomodern::FlexAttributes for usage information.</li>
</ul>
<li><code><a href="http://www.opencalais.com/">http://www.opencalais.com/</a></code> - Calais is a rapidly growing toolkit of capabilities that allow you to readily incorporate state-of-the-art semantic functionality within your blog, content management system, website or application.</li>
<li><code><a href="http://www.aktors.org/technologies/annie/">http://www.aktors.org/technologies/annie/</a></code> - Open Source Information Extraction from The University of Sheffield; ANNIE is an open-source, robust Information Extraction (IE) system which relies on finite state algorithms. ANNIE consists of the following main language processing tools: tokeniser, sentence splitter, POS tagger, named entity recogniser.</li>
<li><code><a href="http://www.searchenginecaffe.com/2007/03/java-open-source-text-mining-and.html">http://www.searchenginecaffe.com/2007/03/java-open-source-text-mining-and.html</a></code> - Jeff Dalton's List of Java Open Source NLP and Text Mining tools</li>
<li><code><a href="http://gate.ac.uk/">http://gate.ac.uk/</a></code> - GATE as an architecture suggests that the elements of software systems that process natural language can usefully be broken down into various types of component, known as resources</li>
<li><code><a href="http://www.casos.cs.cmu.edu/projects/automap/">http://www.casos.cs.cmu.edu/projects/automap/</a></code> - AutoMap is a text mining tool that enables the extraction of network data from texts. AutoMap can extract three types of information: content analytic (words and frequencies), semantic networks, and meta-networks.</li>
<li><code><a href="http://www.netowl.com/" target="_blank">http://www.netowl.com/</a></code> - SRA developed NetOwl®, a suite of rich text mining tools, to discover and extract the knowledge found in free-form text documents and turn it into actionable information. NetOwl has been refined over more than a decade of research and development. Our team of researchers and engineers continue to expand NetOwl’s capabilities to keep pace with evolving information needs.</li>
<li><code><a href="http://www.inxightfedsys.com/products/sdks/tf/default.asp">http://www.inxightfedsys.com/products/sdks/tf/default.asp</a></code> - Out of the box, Inxight ThingFinder automatically identifies and extracts more than 35 key entities - such as people, dates, places, companies or other things - from any text data source, in multiple languages. This ability to automatically identify and classify relevant entities makes ThingFinder one of the most powerful text analysis and extraction tools on the market. Using Inxight ThingFinder, developers can maximize and extend the value of their applications by enabling end-users to quickly find the most important pieces of information within large volumes of documents.</li>
<li><code><a href="http://incubator.apache.org/uima/">http://incubator.apache.org/uima/</a></code> - UIMA enables applications to be decomposed into components, for example "language identification" =&gt; "language specific segmentation" =&gt; "sentence boundary detection" =&gt; "entity detection (person/place names etc.)". Each component implements interfaces defined by the framework and provides self-describing metadata via XML descriptor files. The framework manages these components and the data flow between them. Components are written in Java or C++; the data that flows between components is designed for efficient mapping between these languages.</li>
</ul>
<b>Articles</b> <br />
<ul>
<li><code><a href="http://en.wikipedia.org/wiki/Named_entity_recognition">http://en.wikipedia.org/wiki/Named_entity_recognition</a></code> - Named entity recognition (NER) (also known as entity identification and entity extraction) is a subtask of information extraction that seeks to locate and classify atomic elements in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.</li>
<li><code><a href="http://www.semanticuniverse.com/articles-entity-extraction-and-semantic-web.html">http://www.semanticuniverse.com/articles-entity-extraction-and-semantic-web.html</a></code> - Entity Extraction is the process of automatically extracting document metadata from unstructured text documents.  Extracting key entities such as person names, locations, dates, specialized terms and product terminology from free-form text can empower organizations to not only improve keyword search but also open the door to semantic search, faceted search and document repurposing.  This article defines the field of entity extraction, shows some of the technical challenges involved, and shows how RDF can be used to store document annotations. It then shows how new tools such as Apache UIMA are poised to make entity extraction much more cost effective to an organization.</li>
<li><code><a href="http://broadcast.oreilly.com/2009/02/how-entity-extraction-is-fueli.html">http://broadcast.oreilly.com/2009/02/how-entity-extraction-is-fueli.html</a></code> - How Entity Extraction is Fueling the Semantic Web Fire; short commentary on Apache UIMA and a few other tools.</li>
</ul>
